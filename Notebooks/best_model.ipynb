{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5d2e8b4",
      "metadata": {
        "id": "f5d2e8b4"
      },
      "outputs": [],
      "source": [
        "hyperparameters = {\n",
        "    \"lr\": 1e-4,\n",
        "    \"batch_size\": 1024,\n",
        "    \"embed_dim\": 256,\n",
        "    \"epochs\": 100,\n",
        "    \"num_warmup_steps\": 500,\n",
        "    \"weight_decay\": 1e-4,\n",
        "    \"dropout\": 0.4,\n",
        "    \"num_heads\": 4,\n",
        "    \"num_transformer_layers\": 4,\n",
        "    \"ff_dim\": 512,\n",
        "    \"cnn_out_channels\": 64,\n",
        "    \"k-mers\": 3,\n",
        "    \"max_len\": 199\n",
        "}\n",
        "\n",
        "info = {\n",
        "    \"dataset_size\": \"data\",\n",
        "    \"precision\": \"FP16\",\n",
        "    \"dir_name\": \"Binary Mutation Model\",\n",
        "    \"run\": \"5thRun\",\n",
        "    \"optimizer\": \"Adam\",\n",
        "    \"is_pre_training\": False\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f362d12",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f362d12",
        "outputId": "53ef2bd8-d48a-40c0-8c87-69d098439d79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b9e5e44",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7b9e5e44",
        "outputId": "3f15e7ac-ce03-4648-87a3-0aee45e6677b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1859483, 10)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data_path = f\"/content/drive/MyDrive/{info['dataset_size']}.csv\"\n",
        "\n",
        "datao = pd.read_csv(data_path)\n",
        "datao.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-2lkw2kwUfcs",
      "metadata": {
        "id": "-2lkw2kwUfcs"
      },
      "outputs": [],
      "source": [
        "conflicts = datao.groupby(['sequence', 'ref', 'alt', 'chrom']).label.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iYUnKf8-Ugi6",
      "metadata": {
        "id": "iYUnKf8-Ugi6"
      },
      "outputs": [],
      "source": [
        "conflict_variants = conflicts[conflicts > 1].index\n",
        "datao = datao[~datao.set_index(['sequence', 'ref', 'alt', 'chrom']).index.isin(conflict_variants)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QLwt0DTZUgf2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLwt0DTZUgf2",
        "outputId": "86634b43-4e12-421b-8505-2837c95bc305"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(786865, 10)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = datao[datao['label'] != 2]\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oJ7qVfZ_UlF3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJ7qVfZ_UlF3",
        "outputId": "c6cd8a61-8d5b-4a5f-8fed-21d638d09b84"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2855540279.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['label'] = data['label'].apply(lambda x : 0 if x in [0, 1] else 1)\n"
          ]
        }
      ],
      "source": [
        "data['label'] = data['label'].apply(lambda x : 0 if x in [0, 1] else 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wTOTIn14qm1Q",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "wTOTIn14qm1Q",
        "outputId": "1a5b015b-c295-4a19-c1b4-fdab5849b651"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>700724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>86141</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "label\n",
              "0    700724\n",
              "1     86141\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6Pd2tLfuUlB1",
      "metadata": {
        "id": "6Pd2tLfuUlB1"
      },
      "outputs": [],
      "source": [
        "data1 = data[data['label'] == 1].sample(n=86141, random_state=42)\n",
        "data0 = data[data['label'] == 0].sample(n=100000, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9hbhRGj_Up0A",
      "metadata": {
        "id": "9hbhRGj_Up0A"
      },
      "outputs": [],
      "source": [
        "data = pd.concat([data1, data0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lKMm7lkDUsuQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "lKMm7lkDUsuQ",
        "outputId": "78eb7de7-ca3d-4da7-d8d0-6cea862b54a5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>86141</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "label\n",
              "0    100000\n",
              "1     86141\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21e3fdc2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "21e3fdc2",
        "outputId": "f71e3416-7156-4cc9-8c63-e21f409f24a0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>sequence</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mutation_pos</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ref</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>alt</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mutation_type</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>chrom</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>genomic_pos</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>context_left</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>context_right</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "sequence         0\n",
              "label            0\n",
              "mutation_pos     0\n",
              "ref              0\n",
              "alt              0\n",
              "mutation_type    0\n",
              "chrom            0\n",
              "genomic_pos      0\n",
              "context_left     0\n",
              "context_right    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "S4B_oPJ0oosW",
      "metadata": {
        "id": "S4B_oPJ0oosW"
      },
      "outputs": [],
      "source": [
        "def gc_content(seq):\n",
        "    seq = seq.upper()\n",
        "    gc = seq.count('G') + seq.count('C')\n",
        "    return gc / len(seq)\n",
        "\n",
        "data['gc_content'] = data['sequence'].apply(gc_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3CncEkp-oopa",
      "metadata": {
        "id": "3CncEkp-oopa"
      },
      "outputs": [],
      "source": [
        "def at_content(seq):\n",
        "    seq = seq.upper()\n",
        "    return (seq.count('A') + seq.count('T')) / len(seq)\n",
        "\n",
        "data['at_content'] = data['sequence'].apply(at_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OPAXKwwxoolt",
      "metadata": {
        "id": "OPAXKwwxoolt"
      },
      "outputs": [],
      "source": [
        "def is_cpg_site(row):\n",
        "    seq = row['sequence'].upper()\n",
        "    pos = row['mutation_pos']\n",
        "\n",
        "    if pos < len(seq)-1 and seq[pos] == 'C' and seq[pos+1] == 'G':\n",
        "        return 1\n",
        "\n",
        "    if pos > 0 and seq[pos-1] == 'C' and seq[pos] == 'G':\n",
        "        return 1\n",
        "    return 0\n",
        "\n",
        "data['cpg_flag'] = data.apply(is_cpg_site, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yykadiBVooii",
      "metadata": {
        "id": "yykadiBVooii"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "import numpy as np\n",
        "\n",
        "def sequence_entropy(seq):\n",
        "    counts = Counter(seq)\n",
        "    total = len(seq)\n",
        "    probs = [count / total for count in counts.values()]\n",
        "    return -sum(p * np.log2(p) for p in probs)\n",
        "\n",
        "data['sequence_entropy'] = data['sequence'].apply(sequence_entropy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cvcI78nooee",
      "metadata": {
        "id": "9cvcI78nooee"
      },
      "outputs": [],
      "source": [
        "def is_transition(ref, alt):\n",
        "    transitions = {('A','G'), ('G','A'), ('C','T'), ('T','C')}\n",
        "    return 1 if (ref, alt) in transitions else 0\n",
        "\n",
        "data['is_transition'] = data.apply(lambda row: is_transition(row['ref'], row['alt']), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LRQxmYj2oocW",
      "metadata": {
        "id": "LRQxmYj2oocW"
      },
      "outputs": [],
      "source": [
        "chrom_lengths = {\n",
        "    'chr1': 248956422,\n",
        "    'chr2': 242193529,\n",
        "    'chr3': 198295559,\n",
        "    'chr4': 190214555,\n",
        "    'chr5': 181538259,\n",
        "    'chr6': 170805979,\n",
        "    'chr7': 159345973,\n",
        "    'chr8': 145138636,\n",
        "    'chr9': 138394717,\n",
        "    'chr10': 133797422,\n",
        "    'chr11': 135086622,\n",
        "    'chr12': 133275309,\n",
        "    'chr13': 114364328,\n",
        "    'chr14': 107043718,\n",
        "    'chr15': 101991189,\n",
        "    'chr16': 90338345,\n",
        "    'chr17': 83257441,\n",
        "    'chr18': 80373285,\n",
        "    'chr19': 58617616,\n",
        "    'chr20': 64444167,\n",
        "    'chr21': 46709983,\n",
        "    'chr22': 50818468,\n",
        "}\n",
        "\n",
        "def normalized_genomic_pos(row):\n",
        "    chrom = row['chrom']\n",
        "    chrom_length = chrom_lengths.get(chrom, 1)\n",
        "    return row['genomic_pos'] / chrom_length\n",
        "\n",
        "data['genomic_pos_norm'] = data.apply(normalized_genomic_pos, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75c82540",
      "metadata": {
        "id": "75c82540"
      },
      "outputs": [],
      "source": [
        "left_feature = data[['genomic_pos', 'gc_content', 'at_content', 'cpg_flag', 'sequence_entropy', 'is_transition', 'genomic_pos_norm']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9678786",
      "metadata": {
        "id": "a9678786"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "mutation_type_encoder = OneHotEncoder()\n",
        "chromosome_encoder = OneHotEncoder()\n",
        "ref_encoder = OneHotEncoder()\n",
        "alt_encoder = OneHotEncoder()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "178e40fe",
      "metadata": {
        "id": "178e40fe"
      },
      "outputs": [],
      "source": [
        "# For mutation_type\n",
        "mutation_type_encoder.fit(data[['mutation_type']])\n",
        "mutation_type_data = pd.DataFrame(mutation_type_encoder.transform(data[['mutation_type']]).toarray())\n",
        "mutation_type_data.columns = mutation_type_encoder.get_feature_names_out()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29262ff0",
      "metadata": {
        "id": "29262ff0"
      },
      "outputs": [],
      "source": [
        "# For chrom\n",
        "chromosome_encoder.fit(data[['chrom']])\n",
        "chorm_data = pd.DataFrame(chromosome_encoder.transform(data[['chrom']]).toarray())\n",
        "chorm_data.columns = chromosome_encoder.get_feature_names_out()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73daa918",
      "metadata": {
        "id": "73daa918"
      },
      "outputs": [],
      "source": [
        "# For ref\n",
        "ref_encoder.fit(data[['ref']])\n",
        "ref_data = pd.DataFrame(ref_encoder.transform(data[['ref']]).toarray())\n",
        "ref_data.columns = ref_encoder.get_feature_names_out()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ee7f7a3",
      "metadata": {
        "id": "5ee7f7a3"
      },
      "outputs": [],
      "source": [
        "# For alt\n",
        "alt_encoder.fit(data[['alt']])\n",
        "alt_data = pd.DataFrame(alt_encoder.transform(data[['alt']]).toarray())\n",
        "alt_data.columns = alt_encoder.get_feature_names_out()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fae8e5db",
      "metadata": {
        "id": "fae8e5db"
      },
      "outputs": [],
      "source": [
        "right_features = np.hstack((mutation_type_data, chorm_data, ref_data, alt_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Q-vWRsb1u7MW",
      "metadata": {
        "id": "Q-vWRsb1u7MW"
      },
      "outputs": [],
      "source": [
        "def get_codon(seq, k=hyperparameters['k-mers']):\n",
        "    return [seq[i:i+k] for i in range(len(seq) - k + 1)]\n",
        "\n",
        "vocab = {}\n",
        "\n",
        "for seq in data['sequence']:\n",
        "    for codons in get_codon(seq.lower()):\n",
        "        if codons not in vocab:\n",
        "            vocab[codons] = len(vocab)\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "def get_tensor(text):\n",
        "    return [vocab[codons.lower()] for codons in get_codon(text)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EeuLeQSupFZE",
      "metadata": {
        "id": "EeuLeQSupFZE"
      },
      "outputs": [],
      "source": [
        "x = data['sequence'].values\n",
        "extra_features = np.hstack((left_feature, right_features))\n",
        "y = data['label'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3pSyJMWspGH1",
      "metadata": {
        "id": "3pSyJMWspGH1"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "feature_scaler = StandardScaler()\n",
        "scaled_features = feature_scaler.fit_transform(extra_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "018eefee",
      "metadata": {
        "id": "018eefee"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, x, extra_features, y):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.extra_features = extra_features\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        seq_tensor = torch.tensor(get_tensor(self.x[index]), dtype=torch.long)\n",
        "        features = torch.tensor(self.extra_features[index], dtype=torch.float32)\n",
        "        y_tensor = torch.tensor(self.y[index], dtype=torch.long)\n",
        "\n",
        "        return seq_tensor, features, y_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mgvlCPnrpGFV",
      "metadata": {
        "id": "mgvlCPnrpGFV"
      },
      "outputs": [],
      "source": [
        "dataset = CustomDataset(x, scaled_features, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pPmusO7lpMud",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPmusO7lpMud",
        "outputId": "ba9cd565-4d0b-40e6-b263-17189eeea8e2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9,  2, 10, 11, 12, 13, 14, 15, 16,\n",
              "         17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,  2, 28, 29, 30,  6,  7,  8,\n",
              "         31, 32, 21, 33, 10,  3, 34,  9, 35, 34, 31, 32, 21, 36,  4,  6,  7,  8,\n",
              "         37, 38, 39, 33, 10,  3,  4,  5,  6, 21, 33, 10,  3, 40,  7, 30,  5,  5,\n",
              "          5,  5, 16,  9,  2, 10, 10, 11, 41, 42, 31, 15, 16, 31, 32, 21, 33, 11,\n",
              "         41, 42, 31, 15, 43, 44, 10, 10,  3,  4, 16, 17, 18, 19,  8, 17, 13, 18,\n",
              "         45, 33,  3, 34, 17, 14, 32,  7,  8, 17, 13,  1, 35, 46, 47,  4, 43, 48,\n",
              "         49, 27, 35, 40,  7, 30,  5, 43, 47, 40, 21, 36,  4,  5, 43, 48, 23, 22,\n",
              "         49, 27, 50, 41, 32, 21, 33, 10,  3, 40,  7, 30,  5,  5, 43, 47, 34,  9,\n",
              "         51, 52, 53, 54, 42,  9, 50, 55, 50, 55, 35, 34, 31, 42, 17, 14, 56, 47,\n",
              "          4, 43, 47, 34, 31, 15, 43, 44, 11, 41, 15,  5,  5,  5, 16, 31, 32, 21,\n",
              "         22]),\n",
              " tensor([-0.7094,  1.1601, -1.1601, -0.3426, -0.2129,  0.7577, -0.4487, -0.1801,\n",
              "         -0.3354, -0.1867, -0.2663, -0.2335,  1.8865, -0.5260, -0.2312, -0.2657,\n",
              "         -0.1846, -0.3298, -0.1821, -0.4057, -0.2438, -0.3246,  4.4505, -0.4468,\n",
              "         -0.3118, -0.2321, -0.2858, -0.2789, -0.2913, -0.2391, -0.2806, -0.4465,\n",
              "          1.4019, -0.7072, -0.4415, -0.6795, -0.4689, -0.4763,  1.4612]),\n",
              " tensor(1))"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "053c2fc0",
      "metadata": {
        "id": "053c2fc0"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import random_split\n",
        "\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0de717b",
      "metadata": {
        "id": "c0de717b"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=hyperparameters['batch_size'],\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=hyperparameters['batch_size'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9506120",
      "metadata": {
        "id": "e9506120"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, embed_dim, max_len=5000):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, embed_dim)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1)\n",
        "        div_term = torch.exp((torch.arange(0, embed_dim, 2)) * (-math.log(10000.0) / embed_dim))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:, :x.size(1), :].to(x.device)\n",
        "        return x\n",
        "\n",
        "\n",
        "class CNNTransformerHybrid(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, num_classes, max_len, num_extra_features,\n",
        "                 # Transformer specific params\n",
        "                 num_heads=8, num_transformer_layers=6, ff_dim=2048,\n",
        "                 # CNN specific params\n",
        "                 cnn_out_channels=64,\n",
        "                 # Common params\n",
        "                 dropout=0.2):\n",
        "\n",
        "        super(CNNTransformerHybrid, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "\n",
        "        self.position_encoding = PositionalEncoding(embed_dim=embed_dim, max_len=max_len)\n",
        "        transformer_encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=embed_dim, nhead=num_heads, dim_feedforward=ff_dim,\n",
        "            dropout=dropout, batch_first=True\n",
        "        )\n",
        "        self.transformer_encoder = nn.TransformerEncoder(\n",
        "            encoder_layer=transformer_encoder_layer,\n",
        "            num_layers=num_transformer_layers\n",
        "        )\n",
        "\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=embed_dim, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2),\n",
        "            nn.Dropout(dropout),\n",
        "\n",
        "            nn.Conv1d(in_channels=256, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2),\n",
        "\n",
        "            nn.Conv1d(in_channels=128, out_channels=cnn_out_channels, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "        cnn_output_len = max_len // 8\n",
        "        flattened_cnn_size = cnn_out_channels * cnn_output_len\n",
        "\n",
        "        combined_features_size = flattened_cnn_size + embed_dim + num_extra_features\n",
        "\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Linear(combined_features_size, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x_sequence, x_features):\n",
        "        embeddings = self.embedding(x_sequence)\n",
        "\n",
        "        transformer_input = self.position_encoding(embeddings)\n",
        "        transformer_output = self.transformer_encoder(transformer_input)\n",
        "\n",
        "        transformer_features = transformer_output.mean(dim=1)\n",
        "\n",
        "        cnn_input = embeddings.permute(0, 2, 1)\n",
        "        cnn_output = self.conv_layers(cnn_input)\n",
        "        cnn_features = torch.flatten(cnn_output, 1)\n",
        "\n",
        "        combined_features = torch.cat([transformer_features, cnn_features, x_features], dim=1)\n",
        "\n",
        "        output = self.fc_layers(combined_features)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4a9740e",
      "metadata": {
        "id": "e4a9740e"
      },
      "outputs": [],
      "source": [
        "model = CNNTransformerHybrid(\n",
        "    vocab_size = len(vocab),\n",
        "    embed_dim = hyperparameters['embed_dim'],\n",
        "    num_classes = 2,\n",
        "    max_len = hyperparameters['max_len'],\n",
        "    dropout = hyperparameters['dropout'],\n",
        "    num_heads = hyperparameters['num_heads'],\n",
        "    num_transformer_layers = hyperparameters['num_transformer_layers'],\n",
        "    ff_dim = hyperparameters['ff_dim'],\n",
        "    cnn_out_channels = hyperparameters['cnn_out_channels'],\n",
        "    num_extra_features = extra_features.shape[1],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "801369b8",
      "metadata": {
        "id": "801369b8"
      },
      "outputs": [],
      "source": [
        "if info['is_pre_training']:\n",
        "    checkpoint = torch.load(f\"/content/drive/MyDrive/{info['dir_name']}/model4thRun_epoch_60.pth\")\n",
        "\n",
        "    start_epoch = checkpoint['epoch']\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a446a98c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a446a98c",
        "outputId": "cd86743f-b66c-4065-b425-67a091bfdb18"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CNNTransformerHybrid(\n",
              "  (embedding): Embedding(64, 256, padding_idx=0)\n",
              "  (position_encoding): PositionalEncoding()\n",
              "  (transformer_encoder): TransformerEncoder(\n",
              "    (layers): ModuleList(\n",
              "      (0-3): 4 x TransformerEncoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
              "        (dropout): Dropout(p=0.4, inplace=False)\n",
              "        (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
              "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.4, inplace=False)\n",
              "        (dropout2): Dropout(p=0.4, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (conv_layers): Sequential(\n",
              "    (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Dropout(p=0.4, inplace=False)\n",
              "    (4): Conv1d(256, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "    (5): ReLU()\n",
              "    (6): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (7): Conv1d(128, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "    (8): ReLU()\n",
              "    (9): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Dropout(p=0.4, inplace=False)\n",
              "  )\n",
              "  (fc_layers): Sequential(\n",
              "    (0): Linear(in_features=1831, out_features=256, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=256, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0ae4124",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0ae4124",
        "outputId": "9b4b01a1-2210-4e8d-aa57-ed2bfea879cf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nuNaSIv-u7Ma",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuNaSIv-u7Ma",
        "outputId": "2988a936-e963-4445-bbef-293aa59747be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total trainable parameters: 2914754\n"
          ]
        }
      ],
      "source": [
        "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"Total trainable parameters: {num_params}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EYPt3ma6u7Ma",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYPt3ma6u7Ma",
        "outputId": "3a6d6ddb-a5df-47fe-8737-20be0735310c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-4289989817.py:5: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n"
          ]
        }
      ],
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "ce = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "num_training_steps = len(train_loader) * hyperparameters['epochs']\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=hyperparameters['num_warmup_steps'],\n",
        "    num_training_steps=num_training_steps\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a0279ae",
      "metadata": {
        "id": "8a0279ae"
      },
      "outputs": [],
      "source": [
        "def train(model, loader, ce, optimizer, scaler, scheduler):\n",
        "    model.train()\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "\n",
        "    for x, features, y in loader:\n",
        "        optimizer.zero_grad()\n",
        "        x = x.to(device)\n",
        "        features = features.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        with torch.amp.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
        "            output = model(x, features)\n",
        "            loss = ce(output, y)\n",
        "\n",
        "        prediction = torch.argmax(output, dim=1)\n",
        "        correct += (prediction == y).sum().item()\n",
        "        total += len(x)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        running_loss += loss.item() * len(x)\n",
        "\n",
        "    accuracy = correct / total\n",
        "    return (\n",
        "        running_loss / len(loader.dataset),\n",
        "        accuracy\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9kYaZA-2u7Mb",
      "metadata": {
        "id": "9kYaZA-2u7Mb"
      },
      "outputs": [],
      "source": [
        "def validation(model, loader, ce):\n",
        "    model.eval()\n",
        "\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, features, y in loader:\n",
        "            x = x.to(device)\n",
        "            features = features.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            with torch.amp.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
        "                output = model(x, features)\n",
        "                loss = ce(output, y)\n",
        "\n",
        "            running_loss += loss.item() * len(x)\n",
        "\n",
        "            prediction = torch.argmax(output, dim=1)\n",
        "            correct += (prediction == y).sum().item()\n",
        "\n",
        "            total += len(x)\n",
        "\n",
        "    accuracy = correct / total\n",
        "\n",
        "    return (\n",
        "        running_loss / len(loader.dataset),\n",
        "        accuracy\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9bf1e3c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "e9bf1e3c",
        "outputId": "df303713-ede5-47d6-8926-8b9a5072b26d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch (1/100): Train Loss = 0.7869, Valitation Loss = 0.6650, Train_acc = 0.5309, Val_acc = 0.6041\n",
            "Epoch (2/100): Train Loss = 0.7119, Valitation Loss = 0.6444, Train_acc = 0.5779, Val_acc = 0.6274\n",
            "Epoch (3/100): Train Loss = 0.6761, Valitation Loss = 0.7624, Train_acc = 0.6018, Val_acc = 0.5443\n",
            "Epoch (4/100): Train Loss = 0.6141, Valitation Loss = 0.5705, Train_acc = 0.6664, Val_acc = 0.7018\n",
            "Epoch (5/100): Train Loss = 0.5749, Valitation Loss = 0.5718, Train_acc = 0.7000, Val_acc = 0.7050\n",
            "Epoch (6/100): Train Loss = 0.5519, Valitation Loss = 0.5730, Train_acc = 0.7193, Val_acc = 0.7058\n",
            "Epoch (7/100): Train Loss = 0.5351, Valitation Loss = 0.5382, Train_acc = 0.7313, Val_acc = 0.7313\n",
            "Epoch (8/100): Train Loss = 0.5218, Valitation Loss = 0.5225, Train_acc = 0.7411, Val_acc = 0.7426\n",
            "Epoch (9/100): Train Loss = 0.5110, Valitation Loss = 0.5078, Train_acc = 0.7504, Val_acc = 0.7517\n",
            "Epoch (10/100): Train Loss = 0.4983, Valitation Loss = 0.4902, Train_acc = 0.7586, Val_acc = 0.7632\n",
            "Model saved at /content/drive/MyDrive/Binary Mutation Model/model5thRun_epoch_10.pth\n",
            "Epoch (11/100): Train Loss = 0.4779, Valitation Loss = 0.4543, Train_acc = 0.7717, Val_acc = 0.7883\n",
            "Epoch (12/100): Train Loss = 0.4549, Valitation Loss = 0.4469, Train_acc = 0.7866, Val_acc = 0.7932\n",
            "Epoch (13/100): Train Loss = 0.4382, Valitation Loss = 0.4323, Train_acc = 0.7971, Val_acc = 0.8005\n",
            "Epoch (14/100): Train Loss = 0.4268, Valitation Loss = 0.4144, Train_acc = 0.8048, Val_acc = 0.8127\n",
            "Epoch (15/100): Train Loss = 0.4142, Valitation Loss = 0.4096, Train_acc = 0.8113, Val_acc = 0.8139\n",
            "Epoch (16/100): Train Loss = 0.4033, Valitation Loss = 0.3918, Train_acc = 0.8173, Val_acc = 0.8244\n",
            "Epoch (17/100): Train Loss = 0.3954, Valitation Loss = 0.3835, Train_acc = 0.8219, Val_acc = 0.8277\n",
            "Epoch (18/100): Train Loss = 0.3874, Valitation Loss = 0.3754, Train_acc = 0.8255, Val_acc = 0.8312\n",
            "Epoch (19/100): Train Loss = 0.3787, Valitation Loss = 0.3854, Train_acc = 0.8308, Val_acc = 0.8281\n",
            "Epoch (20/100): Train Loss = 0.3708, Valitation Loss = 0.3772, Train_acc = 0.8353, Val_acc = 0.8356\n",
            "Model saved at /content/drive/MyDrive/Binary Mutation Model/model5thRun_epoch_20.pth\n",
            "Epoch (21/100): Train Loss = 0.3646, Valitation Loss = 0.3618, Train_acc = 0.8383, Val_acc = 0.8417\n",
            "Epoch (22/100): Train Loss = 0.3584, Valitation Loss = 0.3624, Train_acc = 0.8401, Val_acc = 0.8438\n",
            "Epoch (23/100): Train Loss = 0.3541, Valitation Loss = 0.3558, Train_acc = 0.8442, Val_acc = 0.8461\n",
            "Epoch (24/100): Train Loss = 0.3478, Valitation Loss = 0.3532, Train_acc = 0.8478, Val_acc = 0.8460\n",
            "Epoch (25/100): Train Loss = 0.3415, Valitation Loss = 0.3464, Train_acc = 0.8507, Val_acc = 0.8513\n",
            "Epoch (26/100): Train Loss = 0.3372, Valitation Loss = 0.3525, Train_acc = 0.8531, Val_acc = 0.8491\n",
            "Epoch (27/100): Train Loss = 0.3315, Valitation Loss = 0.3454, Train_acc = 0.8548, Val_acc = 0.8510\n",
            "Epoch (28/100): Train Loss = 0.3298, Valitation Loss = 0.3422, Train_acc = 0.8560, Val_acc = 0.8525\n",
            "Epoch (29/100): Train Loss = 0.3243, Valitation Loss = 0.3392, Train_acc = 0.8594, Val_acc = 0.8542\n",
            "Epoch (30/100): Train Loss = 0.3199, Valitation Loss = 0.3378, Train_acc = 0.8600, Val_acc = 0.8555\n",
            "Model saved at /content/drive/MyDrive/Binary Mutation Model/model5thRun_epoch_30.pth\n",
            "Epoch (31/100): Train Loss = 0.3164, Valitation Loss = 0.3339, Train_acc = 0.8624, Val_acc = 0.8562\n",
            "Epoch (32/100): Train Loss = 0.3115, Valitation Loss = 0.3409, Train_acc = 0.8651, Val_acc = 0.8549\n",
            "Epoch (33/100): Train Loss = 0.3089, Valitation Loss = 0.3321, Train_acc = 0.8662, Val_acc = 0.8606\n",
            "Epoch (34/100): Train Loss = 0.3049, Valitation Loss = 0.3302, Train_acc = 0.8688, Val_acc = 0.8592\n",
            "Epoch (35/100): Train Loss = 0.3020, Valitation Loss = 0.3294, Train_acc = 0.8697, Val_acc = 0.8611\n",
            "Epoch (36/100): Train Loss = 0.2981, Valitation Loss = 0.3281, Train_acc = 0.8725, Val_acc = 0.8627\n",
            "Epoch (37/100): Train Loss = 0.2976, Valitation Loss = 0.3313, Train_acc = 0.8726, Val_acc = 0.8617\n",
            "Epoch (38/100): Train Loss = 0.2927, Valitation Loss = 0.3314, Train_acc = 0.8741, Val_acc = 0.8597\n",
            "Epoch (39/100): Train Loss = 0.2917, Valitation Loss = 0.3200, Train_acc = 0.8752, Val_acc = 0.8647\n",
            "Epoch (40/100): Train Loss = 0.2869, Valitation Loss = 0.3338, Train_acc = 0.8771, Val_acc = 0.8581\n",
            "Model saved at /content/drive/MyDrive/Binary Mutation Model/model5thRun_epoch_40.pth\n",
            "Epoch (41/100): Train Loss = 0.2852, Valitation Loss = 0.3246, Train_acc = 0.8780, Val_acc = 0.8648\n",
            "Epoch (42/100): Train Loss = 0.2824, Valitation Loss = 0.3258, Train_acc = 0.8793, Val_acc = 0.8639\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-388558994.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     current_train_loss, current_train_acc = train(\n\u001b[0m\u001b[1;32m     19\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m           \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-357651027.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, loader, ce, optimizer, scaler, scheduler)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    463\u001b[0m         ), \"No inf checks were recorded for this optimizer.\"\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stage\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTEPPED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36m_maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    357\u001b[0m     ) -> Optional[float]:\n\u001b[1;32m    358\u001b[0m         \u001b[0mretval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    357\u001b[0m     ) -> Optional[float]:\n\u001b[1;32m    358\u001b[0m         \u001b[0mretval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "patience = 10\n",
        "best_val_loss = float('inf')\n",
        "counter = 0\n",
        "early_stop = False\n",
        "\n",
        "train_loss_history = []\n",
        "train_acc_history = []\n",
        "\n",
        "val_loss_history = []\n",
        "val_acc_history = []\n",
        "\n",
        "save_dir = f\"/content/drive/MyDrive/{info['dir_name']}\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "for epoch in range(1, hyperparameters['epochs']+1):\n",
        "    current_train_loss, current_train_acc = train(\n",
        "          model,\n",
        "          train_loader,\n",
        "          ce,\n",
        "          optimizer,\n",
        "          scaler,\n",
        "          scheduler\n",
        "      )\n",
        "\n",
        "    current_val_loss, current_val_acc = validation(\n",
        "        model,\n",
        "        test_loader,\n",
        "        ce\n",
        "    )\n",
        "\n",
        "    train_loss_history.append(current_train_loss)\n",
        "    train_acc_history.append(current_train_acc)\n",
        "\n",
        "    val_loss_history.append(current_val_loss)\n",
        "    val_acc_history.append(current_val_acc)\n",
        "\n",
        "    print(f\"Epoch ({epoch}/{hyperparameters['epochs']}): Train Loss = {current_train_loss:.4f}, Valitation Loss = {current_val_loss:.4f}, Train_acc = {current_train_acc:.4f}, Val_acc = {current_val_acc:.4f}\")\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        checkpoint_path = f\"{save_dir}/model{info['run']}_epoch_{epoch}.pth\"\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'encoders': {\n",
        "                'mutation_type': mutation_type_encoder,\n",
        "                'chromosome': chromosome_encoder,\n",
        "                'ref': ref_encoder,\n",
        "                'alt': alt_encoder\n",
        "            },\n",
        "            'feature_scaler': feature_scaler,\n",
        "            'hyperparameters': hyperparameters,\n",
        "            'vocab': vocab\n",
        "        }, checkpoint_path)\n",
        "        print(f\"Model saved at {checkpoint_path}\")\n",
        "\n",
        "        if current_val_loss < best_val_loss:\n",
        "            best_val_loss = current_val_loss\n",
        "            counter = 0\n",
        "            continue\n",
        "        else:\n",
        "            counter += 1\n",
        "            print(f\"No improvement in val loss Counter = {counter}/{patience}\")\n",
        "            if counter >= patience:\n",
        "                print(\"Early stopping triggered!\")\n",
        "                early_stop = True\n",
        "                break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AxBtYij_u7Mb",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "AxBtYij_u7Mb"
      },
      "outputs": [],
      "source": [
        "def get_predictions_and_labels(model, loader):\n",
        "    model.eval()\n",
        "    all_y_true = []\n",
        "    all_y_pred = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, features, y in loader:\n",
        "            x = x.to(device)\n",
        "            features = features.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            yout = model(x, features)\n",
        "\n",
        "            _, pred_mut = torch.max(yout, 1)\n",
        "\n",
        "            all_y_true.extend(y.cpu().numpy())\n",
        "            all_y_pred.extend(pred_mut.cpu().numpy())\n",
        "\n",
        "    return (\n",
        "        (all_y_true, all_y_pred)\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de749240",
      "metadata": {
        "id": "de749240"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "(y_true, y_pred) = get_predictions_and_labels(model, test_loader)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Classification Report Summary\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\n[1] Classification Report  Mutation Label\")\n",
        "print(\"-\" * 60)\n",
        "print(classification_report(y_true, y_pred))\n",
        "\n",
        "print(\"=\"*60 + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9e1fa06",
      "metadata": {
        "id": "a9e1fa06"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot(xticks_rotation=45)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94c63e8e",
      "metadata": {
        "id": "94c63e8e"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_loss_history, label='Train Loss')\n",
        "plt.plot(val_loss_history, label='Validation Loss')\n",
        "plt.title('Training vs Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_acc_history, label='Train Accuracy')\n",
        "plt.plot(val_acc_history, label='Validation Accuracy')\n",
        "plt.title('Training vs Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bR5aFQVhwKGw",
      "metadata": {
        "id": "bR5aFQVhwKGw"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
